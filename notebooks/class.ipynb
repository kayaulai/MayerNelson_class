{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mayer & Nelson (2020) Phonotactic learning with neural language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#from statsmodels.stats.weightstats import CompareMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_corpus_data(filename):\n",
    "    \"\"\"\n",
    "    Reads input file and coverts it to list of lists, adding word boundary \n",
    "    markers.\n",
    "    \"\"\"\n",
    "    raw_data = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        line = ['<s>'] + line.split(' ') + ['<e>']\n",
    "        raw_data.append(line)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = get_corpus_data(\"../sample_data/corpora/finnish_training.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(string_training_data, dev=True, training_split=60):\n",
    "    random.shuffle(string_training_data)\n",
    "    # all data points need to be padded to the maximum length\n",
    "    max_chars = max([len(x) for x in string_training_data])\n",
    "    string_training_data = [\n",
    "        sequence + ['<p>'] * (max_chars - len(sequence)) \n",
    "        for sequence in string_training_data]\n",
    "    # get the inventory and build both directions of dicts  \n",
    "    # this will store the set of possible phones\n",
    "    inventory = list(set(phone for word in string_training_data for phone in word))\n",
    "    inventory = ['<p>'] + [x for x in inventory if x != '<p>'] #ensure that the padding symbol is at index 0\n",
    "\n",
    "    # dictionaries for looking up the index of a phone and vice versa\n",
    "    phone2ix = {p: ix for (ix, p) in enumerate(inventory)}\n",
    "    ix2phone = {ix: p for (ix, p) in enumerate(inventory)}\n",
    "\n",
    "    as_ixs = [\n",
    "        torch.LongTensor([phone2ix[p] for p in sequence]) \n",
    "        for sequence in string_training_data\n",
    "      ]\n",
    "\n",
    "    if not dev:\n",
    "        training_data = torch.stack(as_ixs, 0)\n",
    "        # simpler make a meaningless tiny dev than to have a different eval \n",
    "        # training method that doesn't compute Dev perplexity\n",
    "        dev = torch.stack(as_ixs[-10:], 0)\n",
    "    else:\n",
    "        split = int(len(as_ixs) * (training_split/100))\n",
    "        training_data = torch.stack(as_ixs[:split], 0)\n",
    "        dev = torch.stack(as_ixs[split:], 0)\n",
    "\n",
    "    return inventory, phone2ix, ix2phone, training_data, dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "inventory, phone2ix, ix2phone, training, dev = process_data(\n",
    "        raw_data, dev=True, training_split=60\n",
    "    )\n",
    "inventory_size = len(inventory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Emb_RNNLM(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Emb_RNNLM, self).__init__()\n",
    "        self.vocab_size = params['inv_size']\n",
    "        self.d_emb = params['d_emb']\n",
    "        self.n_layers = params['num_layers']\n",
    "        self.d_hid = params['d_hid']\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.d_emb)\n",
    "        \n",
    "        # input to recurrent layer, default nonlinearity is tanh\n",
    "        self.i2R = nn.RNN(\n",
    "            self.d_emb, self.d_hid, batch_first=True, num_layers = self.n_layers\n",
    "        )\n",
    "        # recurrent to output layer\n",
    "        self.R2o = nn.Linear(self.d_hid, self.vocab_size)\n",
    "        if params['tied']:\n",
    "            if self.d_emb == self.d_hid:\n",
    "                self.R2o.weight = self.embeddings.weight\n",
    "            else:\n",
    "                print(\"Dimensions don't support tied embeddings\")\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batches, seq_len = batch.size()\n",
    "        embs = self.embeddings(batch)\n",
    "        output, hidden = self.i2R(embs)\n",
    "        outputs = self.R2o(output)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions don't support tied embeddings\n"
     ]
    }
   ],
   "source": [
    "rnn_params = {}\n",
    "rnn_params['d_emb'] = 24\n",
    "rnn_params['d_hid'] = 64\n",
    "rnn_params['num_layers'] = 1\n",
    "rnn_params['batch_size'] = 64\n",
    "rnn_params['learning_rate'] = .005\n",
    "rnn_params['epochs'] = 10\n",
    "rnn_params['tied'] = True\n",
    "rnn_params['inv_size'] = inventory_size\n",
    "RNN = Emb_RNNLM(rnn_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def compute_perplexity(dataset, net, bsz=64):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n",
    "    num_examples, seq_len = dataset.size()\n",
    "    \n",
    "    batches = [(start, start + bsz) for start in\\\n",
    "               range(0, num_examples, bsz)]\n",
    "    \n",
    "    total_unmasked_tokens = 0.\n",
    "    nll = 0.\n",
    "    for b_idx, (start, end) in enumerate(batches):\n",
    "            \n",
    "        batch = dataset[start:end]\n",
    "        ut = torch.nonzero(batch).size(0)\n",
    "        preds = net(batch)\n",
    "        targets = batch[:, 1:].contiguous().view(-1)\n",
    "        preds = preds[:, :-1, :].contiguous().view(-1, net.vocab_size)\n",
    "        loss = criterion(preds, targets)\n",
    "        nll += loss.detach()\n",
    "        total_unmasked_tokens += ut\n",
    "\n",
    "    perplexity = torch.exp(nll / total_unmasked_tokens).cpu()\n",
    "    return perplexity.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_lm(dataset, dev, params, net):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=params['learning_rate'])\n",
    "    num_examples, seq_len = dataset.size()    \n",
    "    batches = [\n",
    "        (start, start + params['batch_size']) \n",
    "        for start in range(0, num_examples, params['batch_size'])\n",
    "    ]\n",
    "    \n",
    "    prev_perplexity = 1e10\n",
    "    for epoch in range(params['epochs']):\n",
    "        ep_loss = 0.\n",
    "        start_time = time.time()\n",
    "        random.shuffle(batches)\n",
    "        \n",
    "        for b_idx, (start, end) in enumerate(batches):\n",
    "            batch = dataset[start:end]\n",
    "            preds = net(batch)\n",
    "            preds = preds[:, :-1, :].contiguous().view(-1, net.vocab_size)\n",
    "            targets = batch[:, 1:].contiguous().view(-1)\n",
    "            loss = criterion(preds, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            ep_loss += loss.detach() \n",
    "        dev_perplexity = compute_perplexity(dev,net)\n",
    "\n",
    "        print('epoch: %d, loss: %0.2f, time: %0.2f sec, dev perplexity: %0.2f' %\n",
    "              (epoch, ep_loss, time.time()-start_time, dev_perplexity))\n",
    "        # stop early criterion, increasing perplexity on dev \n",
    "        if dev_perplexity - prev_perplexity > 0.01:\n",
    "            print('Stop early reached')\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1937.15, time: 11.15 sec, dev perplexity: 6.97\n",
      "epoch: 1, loss: 1832.69, time: 9.71 sec, dev perplexity: 6.72\n",
      "epoch: 2, loss: 1806.62, time: 12.05 sec, dev perplexity: 6.61\n",
      "epoch: 3, loss: 1792.68, time: 20.18 sec, dev perplexity: 6.52\n",
      "epoch: 4, loss: 1784.55, time: 16.06 sec, dev perplexity: 6.48\n",
      "epoch: 5, loss: 1779.31, time: 16.15 sec, dev perplexity: 6.46\n",
      "epoch: 6, loss: 1775.42, time: 10.50 sec, dev perplexity: 6.48\n",
      "epoch: 7, loss: 1773.13, time: 10.30 sec, dev perplexity: 6.47\n",
      "epoch: 8, loss: 1770.58, time: 9.59 sec, dev perplexity: 6.44\n",
      "epoch: 9, loss: 1768.98, time: 9.26 sec, dev perplexity: 6.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Emb_RNNLM(\n",
       "  (embeddings): Embedding(26, 24)\n",
       "  (i2R): RNN(24, 64, batch_first=True)\n",
       "  (R2o): Linear(in_features=64, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lm(training, dev, rnn_params, RNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_probs(input_file, model, phone2ix, out_filename):\n",
    "    inp_file = open(input_file, 'r',encoding='UTF-8')\n",
    "    out_file = open(out_filename,'w',encoding='UTF-8')\n",
    "    data_tens = []\n",
    "    as_strings = []\n",
    "    for line in inp_file:\n",
    "        line = line.rstrip()\n",
    "        as_strings.append(line.replace(' ',''))\n",
    "        line = line.split(' ')\n",
    "        line = ['<s>'] + line + ['<e>']\n",
    "        line_as_tensor = torch.LongTensor([phone2ix[p] for p in line])\n",
    "        data_tens.append(line_as_tensor)\n",
    "\n",
    "    num_points = len(data_tens)\n",
    "\n",
    "    for i,word in enumerate(data_tens):\n",
    "        curr_string = as_strings[i]\n",
    "        out_file.write(curr_string + '\\t' + str(compute_perplexity(word.unsqueeze(0), model).numpy()) + '\\n')\n",
    "    \n",
    "    inp_file.close()\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#RNN.eval()\n",
    "get_probs(\"../sample_data/test_data/finnish_test.txt\",\n",
    "    RNN, phone2ix,\n",
    "    \"../output/finnish.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
